---
marp: true
theme: default
size: 16:9
paginate: true
---

# Презентация: Оценка модели с использованием LoRA

---

## Слайд 1: Введение

**Тема:** Сравнение базовой модели и модели с LoRA

**Цели:**

- Оценить качество базовой модели и модели с LoRA

- Проанализировать улучшения и проблемы

- Объяснить метрики оценки

---

## Слайд 2: Метрики оценки

**Accuracy (Точность):**

- Доля правильных предсказаний ко всем предсказаниям.

- Формула: (TP + TN) / (TP + TN + FP + FN)

- В нашем случае: Accuracy базовой модели = 0.012, LoRA модели = 0.878

**Precision (Точность):**

- Доля правильно предсказанных положительных случаев ко всем предсказанным положительным случаям.

- Формула: TP / (TP + FP)

- В нашем случае: Precision базовой модели = 0.010, LoRA модели = 0.119

**Recall (Полнота):**

- Доля правильно предсказанных положительных случаев ко всем реальным положительным случаям.

- Формула: TP / (TP + FN)

- В нашем случае: Recall базовой модели = 0.067, LoRA модели = 0.037

**F1-score:**

- Гармоническое среднее между Precision и Recall.

- Формула: 2 * (Precision * Recall) / (Precision + Recall)

- В нашем случае: F1-score базовой модели = 0.017, LoRA модели = 0.057

---

## Слайд 3: Результаты на тестовых примерах

| Текст                                      | Базовая модель (Accuracy: 0.000) | LoRA модель (Accuracy: 0.556) |

|--------------------------------------------|------------------------------------|-------------------------------|

| Пример 1                                  | Все предсказания неверные         | 5 из 8 предсказаний верные    |

| Пример 2                                  | Все предсказания неверные         | 2 из 4 предсказаний верные    |

| Пример 3                                  | Все предсказания неверные         | 3 из 7 предсказаний верные    |

| Пример 4                                  | Все предсказания неверные         | 1 из 3 предсказаний верные    |

| Пример 5                                  | Все предсказания неверные         | 5 из 8 предсказаний верные    |

---

## Слайд 4: Результаты на тестовом наборе данных

| Метрика      | Базовая модель | LoRA модель | Улучшение |

|--------------|----------------|--------------|-----------|

| Accuracy     | 0.012          | 0.878        | +0.866    |

| Precision    | 0.010          | 0.119        | +0.109    |

| Recall       | 0.067          | 0.037        | -0.030    |

| F1-score     | 0.017          | 0.057        | +0.039    |

---

## Слайд 5: Детальный отчёт по классам

| Класс       | Precision | Recall | F1-score | Support |

|-------------|-----------|--------|----------|---------|

| Класс 1     | 0.00      | 0.00   | 0.00     | 35      |

| Класс 2     | 0.00      | 0.00   | 0.00     | 40      |

| Класс 3     | 0.12      | 0.18   | 0.14     | 28      |

| Класс 4     | 0.00      | 0.00   | 0.00     | 6       |

| Класс 5     | 0.00      | 0.00   | 0.00     | 25      |

| micro avg   | 0.12      | 0.04   | 0.06     | 134     |

| macro avg   | 0.02      | 0.04   | 0.03     | 134     |

| weighted avg| 0.03      | 0.04   | 0.03     | 134     |

---

## Слайд 6: Анализ результатов

**Плюсы LoRA модели:**

- Значительное улучшение Accuracy (с 0.012 до 0.878)

- Улучшение Precision (с 0.010 до 0.119)

- Улучшение F1-score (с 0.017 до 0.057)

- Модель стала более консервативной, меньше ошибочных предсказаний

**Минусы LoRA модели:**

- Уменьшение Recall (с 0.067 до 0.037)

- Проблемы с распознаванием некоторых классов

---

## Слайд 7: Выводы и рекомендации

**Выводы:**

- LoRA модель значительно лучше базовой по большинству метрик.

- Модель стала более консервативной, что уменьшило количество ложноположительных предсказаний.

- Необходимо улучшить Recall для лучшего распознавания.

**Рекомендации:**

- Увеличить количество данных для обучения.

- Улучшить балансировку классов в обучающем наборе данных.

- Попробовать другие параметры LoRA (например, увеличить `r` и `lora_alpha`).

- Использовать более сложные архитектуры или методы аугментации данных.

---

## Слайд 8: Заключение

**Итоги:**

- LoRA адаптеры значительно улучшили качество модели.

- Необходимы дальнейшие улучшения для повышения Recall.

- Метрики показывают, что модель стала более точной и надежной.

**Благодарности:**

- Спасибо за внимание!

- Вопросы?

---

## Пояснения к метрикам:

1. **Accuracy (Точность):**

   - Показывает общую долю правильных предсказаний. Высокое значение (0.878 для LoRA) говорит о том, что модель в целом хорошо предсказывает.

2. **Precision (Точность):**

   - Показывает, насколько точно модель предсказывает положительные случаи. Улучшение с 0.010 до 0.119 говорит о том, что LoRA модель стала лучше предсказывать.

3. **Recall (Полнота):**

   - Показывает, насколько полно модель находит все положительные случаи. Уменьшение с 0.067 до 0.037 говорит о том, что LoRA модель стала пропускать некоторые случаи.

4. **F1-score:**

   - Гармоническое среднее между Precision и Recall. Улучшение с 0.017 до 0.057 говорит о балансе между точностью и полнотой.